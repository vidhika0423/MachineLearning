{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4f58e4",
   "metadata": {},
   "source": [
    "Classification of text documents using sparse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce2924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\"\n",
    "]\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "def load_dataset(verbose=False, remove=()):\n",
    "    \"\"\"load and vectorize the 20 newspaper datasets\"\"\"\n",
    "\n",
    "    data_train = fetch_20newsgroups(\n",
    "        subset = \"train\",\n",
    "        categories= categories,\n",
    "        shuffle = True,\n",
    "        random_state = 42,\n",
    "        remove = remove\n",
    "    )\n",
    "\n",
    "    data_test = fetch_20newsgroups(\n",
    "        subset = \"test\",\n",
    "        categories=categories,\n",
    "        shuffle = True,\n",
    "        random_state=42,\n",
    "        remove = remove\n",
    "    )\n",
    "\n",
    "    target_names = data_train.target_names\n",
    "\n",
    "    y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "    t0 = time()\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True, \n",
    "        max_df=0.5,\n",
    "        min_df=5,\n",
    "        stop_words=\"english\"\n",
    "    )\n",
    "\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "    duration_train = time()- t0\n",
    "\n",
    "    t0 = time()\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    duration_test = time() - t0\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    if verbose:\n",
    "        # compute size of data\n",
    "        data_train_size_mb = size_mb(data_train.data)\n",
    "        data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "        print(\n",
    "            f\"{len(data_train.data)} documents - \"\n",
    "            f\"{data_train_size_mb: .2f}MB (training set)\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{len(data_test.data)} documents - {data_test_size_mb: .2f}MB (test set)\"\n",
    "        )\n",
    "\n",
    "        print(f\"{len(target_names)} categories\")\n",
    "\n",
    "        print(\n",
    "            f\"vectorize training done in {duration_train: .3f}s\"\n",
    "            f\" at {data_train_size_mb/ duration_train: .3f} MB/s\"\n",
    "        )\n",
    "\n",
    "        print(f\"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}\")\n",
    "\n",
    "        print(\n",
    "            f\"vectorize testing done in {duration_test:.3f}s\"\n",
    "            f\"at {data_test_size_mb / duration_test:.3f}MB/s\"\n",
    "        )\n",
    "\n",
    "        print(f\"n_samples: {X_test.shape[0]}, n_features: {X_test.shape[1]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, feature_names, target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a6044",
   "metadata": {},
   "source": [
    "Analysis of a bag-of-words document classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c5ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 documents -  3.98MB (training set)\n",
      "1353 documents -  2.87MB (test set)\n",
      "4 categories\n",
      "vectorize training done in  0.592s at  6.721 MB/s\n",
      "n_samples: 2034, n_features: 7831\n",
      "vectorize testing done in 0.391sat 7.327MB/s\n",
      "n_samples: 1353, n_features: 7831\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train , y_test, feature_names , target_names = load_dataset(\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5bb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf = RidgeClassifier(tol = 1e-2, solver = \"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
